{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=darkcyan>  Introduction and application to dimension reduction in Python </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=darkred>  Generate random numbers with NumPy </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Arrays of random numbers are generated with the ``rand()`` NumPy function.\n",
    "``rand()`` takes the the size of the array as an argument.\n",
    "\n",
    "- Arrays of random integers are generated using the ``randint()`` NumPy function.\n",
    "``randint()`` has three arguments, the lower end of the range, the upper end of the range, and the number of integer values to generate.\n",
    "\n",
    "- Arrays of standard Gaussian random values are generated using the ``randn()`` NumPy function.\n",
    "``randn()`` takes the the size of the array as an argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional information on random sampling with NumPy here: https://numpy.org/doc/1.16/reference/routines.random.html\n",
    "\n",
    "**Do not hesitate to try other distributions and understand the arguments of all functions**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "    \n",
    "- Generate 10 random numbers from the previous distributions: uniform in (0,1), uniform in {0,...,10}, standard Gaussian. \n",
    "    \n",
    "- Generate 10 random numbers from a Gaussian distribution with mean 1 and variance 2.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n= 10 \n",
    "values_uni = np.random.rand(n)\n",
    "print(values_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also sample multivariate normal with ``np.random.multivariate_normal``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = [0, 0]\n",
    "Sigma = [[1, 0], [0, 1]]\n",
    "n = 1000\n",
    "# Sample n Gaussian random variables with mean m and variance matrix Sigma \n",
    "x, y = np.random.multivariate_normal(m, Sigma, n).T\n",
    "plt.plot(x, y, '.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "    \n",
    "- Generate 500 Gaussian random variables with mean $(-1,1)$ and variance $\\begin{pmatrix}2 & 0.5 \\\\ 0.5 & 1\\end{pmatrix}$.\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also have a look at ``scipy.stats`` https://docs.scipy.org/doc/scipy/reference/stats.html#module-scipy.stats\n",
    "This is a module containing many probability distributions and functions very useful in statistics and applied probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=darkred> Arrays/list/tuples syntax in Python </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://numpy.org/doc/stable/reference/generated/numpy.array.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy arrays can be defined using lists [...] and tuples (...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 3, 4, 5, 6, 7, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If we want to access index 3 and 4 \n",
    "x[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If we want to access all elements except the last one\n",
    "x[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If we want to access all elements except the two last ones\n",
    "x[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If we want to revert the order of the elements\n",
    "x[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also build arrays with any dimension by specifying how many dimensions and length along that dimension in a tuple or list. This can be done for instance using ``np.zeros`` or ``np.ones``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros((4, 3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ones((2, 2, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also reshape an array using the function ``np.reshape`` (https://numpy.org/doc/stable/reference/generated/numpy.reshape.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "   Convert the following 1D array to a 2D array with two rows.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(20)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``np.dot`` function computes the dot product between two arrays. \n",
    "If both arrays are one-dimensional, it computes the inner product of vectors.\n",
    "If both arrays are two-dimensional, it computes the matrix multiplication. But it extends dot product to higher-dimensional arrays.\n",
    "https://numpy.org/doc/stable/reference/generated/numpy.dot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[1, 0], [0, 1]]\n",
    "y = [[2, 2], [0, 3]]\n",
    "np.dot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "    Compute the product between  $\\begin{pmatrix}2 & 0.5 \\\\ 0.5 & 1\\end{pmatrix}$ and  $\\begin{pmatrix}3 & 1 & 0\\\\ 1 & 1 & 1\\end{pmatrix}$.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=darkred>  Singular Value Decomposition </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Singular Value Decomposition (SVD) states that for all $\\mathbb{R}^{n \\times d}$ matrix $A$ with rank $r$, there exist $\\sigma_1\\geqslant \\ldots \\geqslant \\sigma_r>0$ such that\n",
    "$$\n",
    "A = \\sum_{k=1}^r \\sigma_k u_k v_k'\\,,\n",
    "$$\n",
    "where $\\{u_1,\\ldots,u_r\\}\\in (\\mathbb{R}^n)^r$ and $\\{v_1,\\ldots,v_r\\}\\in (\\mathbb{R}^d)^r$ are two orthonormal families. The vectors $\\{\\sigma_1,\\ldots,\\sigma_r\\}$ are called singular values of $A$ and $\\{u_1,\\ldots,u_r\\}$ (resp. $\\{v_1,\\ldots,v_r\\}$) are the left-singular (resp. right-singular) vectors of $A$.\n",
    "\n",
    "\n",
    "1. If $U$ denotes the $\\mathbb{R}^{n\\times r}$ matrix with columns given by $\\{u_1,\\ldots,u_r\\}$ and $V$ denotes the $\\mathbb{R}^{p \\times r}$ matrix with columns given by $\\{v_1,\\ldots,v_r\\}$, then the singular value decomposition of $A$ may also be written as\n",
    "$$\n",
    "A = UD_rV'\\,,\n",
    "$$\n",
    "where $D_r = \\mathrm{diag}(\\sigma_1,\\ldots,\\sigma_r)$.\n",
    "\n",
    "\n",
    "2. The singular value decomposition is closely related to the spectral theorem for symmetric semipositive definite matrices. In the framework of this practical session, $A'A$ and $AA'$ are positive semidefinite such that\n",
    "$$\n",
    "A'A = VD_r^2V'\\quad\\mathrm{and}\\quad AA' = UD_r^2U'\\,.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numpy.linalg.svd function can be used in Python to compute the SVD of a given matrix. The output of this function are:\n",
    "1. $U$ has left singular vectors in the columns ;\n",
    "2. sigma is rank 1 numpy array with singular values ;\n",
    "3. $V$ has right singular vectors in the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings for better clarity (may not be the best thing to do)...\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "# Image.open is used to open the input picture (with any .jpg or .png)\n",
    "img = Image.open('./seals.jpg')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image converted into a numpy array or matrix\n",
    "img_mat       = np.array(list(img.getdata(band=0)), float)\n",
    "img_mat.shape = (img.size[1], img.size[0])\n",
    "img_mat       = np.matrix(img_mat)\n",
    "# SVD can then be applied to the matrix img_mat\n",
    "img_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "    Use the ``np.linalg.svd`` function to compute the SVD of img_mat\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://numpy.org/doc/stable/reference/generated/numpy.linalg.svd.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Singular Value Decomposition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "    Perform image reconstruction using only k = 10 singular values. Display several reconstruction using different values of k.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image reconstruction\n",
    "k = 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "    Write a function with input the path of an image \"path_image\" and an integer \"k\" and return in gray scale the reconstructed picture with the first k singular values\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_decomposition(path_image,k):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=darkred>  Principal Component Analysis </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=darkred>Application of the SVD to Principal Component Analysis</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $(X_i)_{1\\leqslant i\\leqslant n}$ be i.i.d. random variables in $\\mathbb{R}^d$ and consider the matrix $X\\in\\mathbb{R}^{n\\times d}$ such that the $i$-th row of $X$ is the observation $X'_i$. Let $\\Sigma_n$ be the empirical covariance matrix (data are assumed to be centered for simplicity, this can be done manually):\n",
    "$$\n",
    "\\Sigma_n = n^{-1}\\sum_{i=1}^n X_i X'_i\\,.\n",
    "$$\n",
    "Principal Component Analysis  aims at reducing the dimensionality of the observations $(X_i)_{1\\leqslant i \\leqslant n}$ using a \"compression\" matrix $W\\in \\mathbb{R}^{p\\times d}$ with $p\\leqslant d$ so that for each $1\\leqslant i \\leqslant n$, $WX_i$ ia a low dimensional representation of $X_i$. The original observation may then be partially recovered using another matrix $U\\in \\mathbb{R}^{d\\times p}$. Principal Component Analysis computes $U$ and $W$ using the least squares approach:\n",
    "$$\n",
    "(U_{\\star},W_{\\star}) \\in \\hspace{-0.5cm}\\underset{(U,W)\\in \\mathbb{R}^{d\\times p}\\times \\mathbb{R}^{p\\times d}}{\\mathrm{argmin}} \\;\\sum_{i=1}^n\\|X_i - UWX_i\\|^2\\,, \n",
    "$$\n",
    "\n",
    "Let $(U_{\\star},W_{\\star})\\in \\mathbb{R}^{d\\times p}\\times \\mathbb{R}^{p\\times d}$ be a solution to this problem. Then, it can be proved that the columns of $U_{\\star}$ are orthonormal and $W_{\\star} = U_{\\star}'$. Therefore, solving the optimization problem boils down to computing\n",
    "$$\n",
    "U_{\\star} \\in \\hspace{-0.5cm}\\underset{U\\in \\mathbb{R}^{d\\times p}\\,,\\, U'U = I_n}{\\mathrm{argmax}} \\hspace{-.4cm}\\{ \\mathrm{trace}(U'\\Sigma_nU)\\}\\,.\n",
    "$$\n",
    "Let $\\{\\vartheta_1,\\ldots,\\vartheta_d\\}$ be orthonormal eigenvectors associated with the eigenvalues $\\lambda_1\\geqslant \\ldots \\geqslant \\lambda_d$ of $\\Sigma_n$. Then a solution is given by the matrix $U_{\\star}$ with columns $\\{\\vartheta_1,\\ldots,\\vartheta_p\\}$ and $W_{\\star} = U_{\\star}'$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=darkred>Principal Component Analysis as an optimization problem</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For any dimension $1\\leqslant p \\leqslant  d$, let $\\mathcal{F}_d^p$ be the set of all vector suspaces of $\\mathbb{R}^d$ with dimension $p$. Principal Component Analysis computes a linear span $V_d$ such as\n",
    "$$\n",
    "V_p \\in \\underset{V\\in \\mathcal{F}_d^p}{\\mathrm{argmin}} \\;\\sum_{i=1}^n\\|X_i - \\pi_V(X_i)\\|^2\\,, \n",
    "$$\n",
    "where $\\pi_V$ is the orthogonal projection onto the linear span $V$. Consequently, $V_1$ is a solution if and only if $v_1$ is solution to:\n",
    "$$\n",
    "v_1 \\in \\underset{v \\in \\mathbb{R}^d\\,;\\, \\|v\\|=1}{\\mathrm{argmax}} \\sum_{i=1}^n   \\langle X_i, v \\rangle^2\\,.\n",
    "$$\n",
    "For all $2\\leqslant p \\leqslant d$, following the same steps, it can be proved that  a solution is given by $V_p = \\mathrm{span}\\{v_1, \\ldots, v_p\\}$ where\n",
    "$$\n",
    "v_1 \\in \\underset{v\\in \\mathbb{R}^d\\,;\\,\\|v\\|=1}{\\mathrm{argmax}} \\sum_{i=1}^n\\langle X_i,v\\rangle^2 \\quad\\mbox{and for all}\\;\\; 2\\leqslant k \\leqslant p\\;,\\;\\; v_k \\in \\underset{\\substack{v\\in \\mathbb{R}^d\\,;\\,\\|v\\|=1\\,;\\\\ v\\perp v_1,\\ldots,v\\perp v_{k-1}}}{\\mathrm{argmax}}\\sum_{i=1}^n\\langle X_i,v\\rangle^2\\,. \n",
    "$$\n",
    "\n",
    "As $V_p = \\mathrm{span}\\{\\vartheta_1, \\ldots, \\vartheta_p\\}$, for all $1\\leqslant i\\leqslant n$,\n",
    "$$\n",
    "\\pi_{V_p}(X_i) = \\sum_{k=1}^p \\langle X_i,\\vartheta_k\\rangle \\vartheta_k  = \\sum_{k=1}^p (X'_i \\vartheta_k)\\vartheta_k = \\sum_{k=1}^p c_k(i)\\vartheta_k\\,,\n",
    "$$\n",
    "where for all $1\\leqslant k \\leqslant p$, the $k$-th principal component is defined as $c_k = X\\vartheta_k$. Therefore the $k$-th principal component is the vector whose components are the coordinates of each $X_i$, $1\\leqslant i\\leqslant n$, relative to the basis $\\{\\vartheta_1, \\ldots, \\vartheta_p\\}$ of $V_p$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Pyplot, the ``scatter()`` function allows to draw a scatter plot.\n",
    "It plots one dot for each observation. It needs two arrays of the same length, one for the values of the x-axis, and one for values on the y-axis.\n",
    "Additional arguments and options about scatter plots can be found here: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = np.random.rand(n)\n",
    "y_values = np.random.rand(n)\n",
    "plt.scatter(x_values,y_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "    Using the ``np.dot`` function, compute the product of a 2x2 matrix containing standard Gaussian random numbers with a 2x200 matrix containing standard Gaussian random numbers. Compute the transpose of this matrix.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " See  https://numpy.org/doc/stable/reference/generated/numpy.dot.html for additional details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "    Use a scatter plot to display the second column of the matrix as a function of the first column.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "    We have a dataset of n=200 points in dimension 2. We want to use a PCA to project data in a one dimensional space. Perform a PCA with one component using PCA(n_components=1) and the function fit.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html for additional details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can display several outputs of the PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The principal component is:')\n",
    "print(pca.components_)\n",
    "\n",
    "print('The explained variance is %g'%pca.explained_variance_)\n",
    "print('The associated singular value is %g'%pca.singular_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply the dimensionality reduction on X\n",
    "# X_pca contains the coordinates of each data in the space generated by the principal components\n",
    "\n",
    "\n",
    "# in this case pca.components_[k] contains the coordinates of the k-th principal component in\n",
    "# the original space (here the usual Euclidian plane). In a general case pca.components_[k] is a \n",
    "# d-dimensional vector.\n",
    "# X_pca[i] contains the coordinates of the i-th data in the vector space generated by the principal \n",
    "# components.\n",
    "# Therefore, X_pca[i] is a vector with n_components entries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a general case, when $\\mathrm{n\\_components} = p$ for all $1\\leqslant i\\leqslant n$ and all $1\\leqslant k \\leqslant p$, the\n",
    "projection of $X_i$ in the space generated by the principal components is:\n",
    "\n",
    "$$\n",
    "\\pi_{V_p}(X_i) = \\sum_{k=1}^{p}X_{\\mathrm{pca}}[i]_k \\times \\mathrm{pca.components\\_}[k]\\,.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "Transform the reduced data set X_pca in the original space using ``pca.inverse_transform`` to build X_inverse. \n",
    "    \n",
    "Use a scatter plot to display X and X_inverse on the same plot.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# transform the reduced data set in the original space\n",
    "# X_inverse[i,:] contains the coordinates of the projection of Xi in the original space\n",
    "\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], alpha=0.2, s=10)\n",
    "plt.scatter(X_inverse[:, 0], X_inverse[:, 1], alpha=0.8, s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
