{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=darkcyan> Multivariate linear regression </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib import colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is assumed that for all $1\\leqslant i \\leqslant n$, \n",
    "\n",
    "$$\n",
    "Y_i = X^\\top_i \\beta_{\\star} + \\varepsilon_i\\,,\n",
    "$$\n",
    "\n",
    "where the $(\\varepsilon_i)_{1\\leqslant i\\leqslant n}$ are i.i.d. random variables in $\\mathbb{R}$, $X_i\\in\\mathbb{R}^d$ and $\\beta_{\\star}$ is an unknown vector in $\\mathbb{R}^d$. Let $Y\\in\\mathbb{R}^n$ (resp. $\\varepsilon\\in\\mathbb{R}^n$)  be the random vector such that  for all $1\\leqslant i \\leqslant n$, the $i$-th component of $Y$ (resp. $\\varepsilon$) is $Y_i$ (resp. $\\varepsilon_i$) and $X\\in\\mathbb{R}^{n\\times d}$ the matrix with line $i$ equal to $X^\\top_i$. The model is then written\n",
    "\n",
    "$$\n",
    "Y = X \\beta_{\\star} + \\varepsilon\\,.\n",
    "$$\n",
    "\n",
    "In this section, it is assumed that $\\mathbb{E}[\\varepsilon] = 0$ and $\\mathbb{E}[\\varepsilon \\varepsilon^\\top] = \\sigma_{\\star}^2 I_n$. The penalized least squares estimate of $\\beta_{\\star}$ is defined as a solution to\n",
    "\n",
    "$$\n",
    "\\widehat \\beta_n\\in  \\mathrm{argmin}_{\\beta\\in\\mathbb{R}^d}\\,\\left( \\|Y - X\\beta\\|_2^2 + \\lambda \\|\\beta\\|_2^2\\right)\\,.\n",
    "$$\n",
    "\n",
    "where $\\lambda>0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred> Explain why the loss function is penalized </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred> Prove that the bias is given by \n",
    "$$\n",
    "\\mathbb{E}[\\widehat \\beta_n] - \\beta_* = - \\lambda(X^\\top X + \\lambda I_d)^{-1}\\beta_*\\,.\n",
    "$$</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>Prove that the variance is given by\n",
    "$$\n",
    "\\mathbb{V}[\\widehat \\beta_n] = \\sigma_\\star^2(X^\\top X + \\lambda I_d)^{-2}X^\\top X\\,.\n",
    "$$</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data frames can be imported using pandas. This provides two-dimensional and heterogeneous tabular data.\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "Import data in the file BRinf using ``read_csv``, display the first rows with ``head`` and the shape of the dataframe using ``shape``.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this section, multivariate linear regression is used to predic the Brazilian inflation based on\n",
    "# many observed variables, see https://github.com/gabrielrvsc/HDeconometrics/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of observations, number of variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "Use the ``StandardScaler`` of sklearn to preprocess the input variables.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``StandardScaler`` standardizes the input variables by removing the mean and scaling to unit variance.\n",
    "We will not analyze closely standardization in this course. However, it is often very useful (even mandatory in some cases) for the stability of learning procedures.\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first coordinate is the number of samples\n",
    "# second coordinate is the number of input features (+ 1 for the observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "Build two datasets. \n",
    "    ``X_train`` and ``Y_train`` contain the first 140 input data and observations. ``X_test`` and ``Y_test`` contain the remaining input data and observations. We train a linear regression model using ``X_train`` and ``Y_train`` and we assess the performance of the model using ``X_test`` and ``Y_test``. \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pandas.pydata.org/docs/reference/frame.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_data_train = 140\n",
    "nb_diff       = df.shape[0]-nb_data_train\n",
    "# inflation observations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression from scractch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "Write a cost function with inputs ``X``, ``Y`` and a regression parameter ``beta``. This function returns the mean squared error between observations and linear predictions.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(X, Y, beta):\n",
    "    n = len(Y)\n",
    "    loss = ###\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "If we do not use the closed form expression of the estimator, we can minimize the cost function using gradient descent. Write a function ``gradient_descent`` which iteratively minimizes the cost function using gradient descent. The arguments of the function are ``X``, ``Y``, the initial estimate ``beta``, a stepsize ``gamma`` and the maximum number of iterations ``n_it``. The function returns the last parameter estimate and the loss values computed at each iteration.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, Y, beta, gamma, iterations):\n",
    "    cost = np.zeros(iterations)\n",
    "    n = len(Y)\n",
    " \n",
    "    for iteration in range(n_it):\n",
    "        \n",
    "        gradient = ###\n",
    "\n",
    "        beta = beta - gamma * gradient\n",
    "        \n",
    "        cost[iteration] = cost_function(X, Y, beta)\n",
    " \n",
    "    return beta, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "Run a training using gradient descent and display the cost function along iterations and the parameter estimate. See the influence of gamma.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Coefficients\n",
    "beta = np.zeros(X_train.shape[1])\n",
    "gamma = 0.01\n",
    "n_it = 10000\n",
    "beta_hat, cost = gradient_descent(X_train, Y_train, beta, gamma, n_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "Compare the true observations and the predictions on the train and test sets.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression using sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "Fit a ``linear_model`` from sklearn to train a linear model (without Ridge penalization).\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "reg_lin = linear_model.Ridge(alpha= 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``train_test_split`` splits arrays or matrices into random train and test subsets. It allows to train several times a model with different training set and analyze the variability of the performance on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "Use train_test_split to train 50 times a linear model using 90% of the data to estimate the unknown parameter and 10% to test the performance of the model. \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
