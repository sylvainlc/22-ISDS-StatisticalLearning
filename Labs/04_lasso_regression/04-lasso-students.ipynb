{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=darkcyan> Multivariate linear regression - Lasso </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib import colors \n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is assumed that for all $1\\leqslant i \\leqslant n$, \n",
    "\n",
    "$$\n",
    "Y_i = X^\\top_i \\beta_{\\star} + \\varepsilon_i\\,,\n",
    "$$\n",
    "\n",
    "where the $(\\varepsilon_i)_{1\\leqslant i\\leqslant n}$ are i.i.d. random variables in $\\mathbb{R}$, $X_i\\in\\mathbb{R}^d$ and $\\beta_{\\star}$ is an unknown vector in $\\mathbb{R}^d$. Let $Y\\in\\mathbb{R}^n$ (resp. $\\varepsilon\\in\\mathbb{R}^n$)  be the random vector such that  for all $1\\leqslant i \\leqslant n$, the $i$-th component of $Y$ (resp. $\\varepsilon$) is $Y_i$ (resp. $\\varepsilon_i$) and $X\\in\\mathbb{R}^{n\\times d}$ the matrix with line $i$ equal to $X^\\top_i$. The model is then written\n",
    "\n",
    "$$\n",
    "Y = X \\beta_{\\star} + \\varepsilon\\,.\n",
    "$$\n",
    "\n",
    "In this section, it is assumed that $\\mathbb{E}[\\varepsilon] = 0$ and $\\mathbb{E}[\\varepsilon \\varepsilon^\\top] = \\sigma_{\\star}^2 I_n$. The Lasso estimate of $\\beta_{\\star}$ is defined as a solution to\n",
    "\n",
    "$$\n",
    "\\widehat \\beta_n\\in  \\mathrm{argmin}_{\\beta\\in\\mathbb{R}^d}\\,\\left( n^{-1}\\|Y - X\\beta\\|_2^2 + \\lambda \\|\\beta\\|_1\\right)\\,,\n",
    "$$\n",
    "\n",
    "where $\\lambda>0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred> Explain the coordinate-wise optimization procedure </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data frames can be imported using pandas. This provides two-dimensional and heterogeneous tabular data.\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "Import data in the file BRinf using ``read_csv``, display the first rows with ``head`` and the shape of the dataframe using ``shape``.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this section, multivariate linear regression is used to predic the Brazilian inflation based on\n",
    "# many observed variables, see https://github.com/gabrielrvsc/HDeconometrics/\n",
    "df = pd.read_csv('BRinf.txt')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of observations, number of variables\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "Use the ``StandardScaler`` of sklearn to preprocess the input variables.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``StandardScaler`` standardizes the input variables by removing the mean and scaling to unit variance.\n",
    "We will not analyze closely standardization in this course. However, it is often very useful (even mandatory in some cases) for the stability of learning procedures.\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "Build two datasets. \n",
    "    ``X_train`` and ``Y_train`` contain the first 140 input data and observations. ``X_test`` and ``Y_test`` contain the remaining input data and observations. We train a linear regression model using ``X_train`` and ``Y_train`` and we assess the performance of the model using ``X_test`` and ``Y_test``. \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pandas.pydata.org/docs/reference/frame.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso Regression from scractch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "Write a ``threshold_function`` function with arguments a real number ``z`` and a positive number ``$\\alpha$`` which returns \n",
    "$$\n",
    "\\begin{cases}\n",
    "z+\\alpha & \\text{if } z<-\\alpha, \\\\\n",
    "z-\\alpha & \\text{if } z>\\alpha, \\\\\n",
    "0 & \\text{otherwise}. \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "    Write a ``coordinate_descent_lasso`` function with arguments an initial estimate ``$\\beta$``, the data ``X`` and ``y``, a penalty parameter ``$\\alpha$`` and a number of iterations ``n_iter``. The function returns the parameter estimate after n_iter iterations of the coordinate-wise optimization procedure.\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make things simpler, you can write the function with $\\alpha = \\lambda n /2$ in the mathematical derivation above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "    Run the algorithm with several values of $\\alpha$ using X_train and Y_train and display the number of zero coeficients of the parameter estimate and the MSE obtained on the test set.\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso Regression with Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, LassoCV, Ridge, RidgeCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "Create a np array with several values of the penalty parameter (called $\\alpha$ in Python)\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "Use the ``fit`` function of sklearn to fit a Lasso model with for each value of $\\alpha$. \n",
    "    \n",
    "Store the estimated parameter, the number of zeros in the estimated parameter and the MSE on the test set after each training.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "Display the estimated parameters as a function of the penalty parameter.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "Display the number of zero coefficients of the estimated parameter as a function of the penalty parameter.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "Display the MSE on the test set as a function of the penalty parameter.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
