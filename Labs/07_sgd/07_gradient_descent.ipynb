{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CF7Q8jEeEPM1"
   },
   "source": [
    "## <font color=darkcyan> Gradient descent for Optimization and Machine/Statistical Learning </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NG6cr03iSYt6"
   },
   "source": [
    "In this notebook, we provide an **overview of gradient-based optimization algorithms** with a specific **focus on first order methods and accelerated algorithms** which are commonly used in statistical/machine/deep learning. Supervised learning applications are usually based on the minimization of an objective function on $\\mathbb{R}^d$ (kernel based SVM models, penalized regression, maximum likelihood estimation of neural networks) and accelerated gradient methods are the go-to solutions to solve these optimization problems.\n",
    "\n",
    "The results provided in this notebook are valid with assumptions on the target functions such as convexity or strong convexity (some of them may be relaxed). Although these algorithms are widely used, keep in mind that these assumptions do not hold in practice and that  non-convexity stems from the arbitrary form of the loss functions used in machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gv1tTxcDjLW6"
   },
   "source": [
    "### <font color=darkred> Bibliography & additional ressources </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SLsK5IHEjPWb"
   },
   "source": [
    "- [1] Convex Optimization, S. Boyd & L. Vandenberghe, 2009, https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf\n",
    "``Very complete book on convex optimization and gradient descent algorithms (full gradient, Newton's method, constrained problems)``\n",
    ", etc.\n",
    "- [2] Convex Optimization: Algorithms and\n",
    "Complexity, S. Bubeck, 2015, https://arxiv.org/pdf/1405.4980.pdf\n",
    "\n",
    "-  [3] Probabilistic machine learning: an introduction, Kevin P. Murphy, 2022, https://probml.github.io/pml-book/book1.html\n",
    "``Full book online with all basics on machine learning. Not state-of-the-art but very good introduction``\n",
    "\n",
    "- [4] Learning theory from first principles, F. Bach, 2023, https://www.di.ens.fr/~fbach/ltfp_book.pdf\n",
    "``Much more advanced reference, Chapter 5 on optimization``\n",
    "\n",
    "- [5] Algorithms for optimization, M. J. Kochenderfer and T. A. Wheeler, 2019.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B61KWCTMHjsy"
   },
   "source": [
    "### <font color=darkred>Introduction : general framework & motivations</font>\n",
    "\n",
    "Parameter inference in machine learning often boils down to solving\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathrm{argmin}_{w \\in \\mathbb{R}^d} \\,\\{f(w) + \\lambda \\mathrm{pen}(w)\\}\\,,\n",
    "\\end{equation*}\n",
    "\n",
    "with $\\lambda>0$, $\\mathrm{pen}(\\cdot)$ some penalization function and $f$ a ``goodness-of-fit function``  based on a loss $\\ell$,\n",
    "\n",
    "\\begin{equation*}\n",
    "f(w) = \\frac 1n \\sum_{i=1}^n \\ell(y_i, \\langle w, x_i \\rangle)\\,,\n",
    "\\end{equation*}\n",
    "\n",
    " where $(x_i,y_i)_{1\\leq i\\leq n}$ are ``training examples of inputs and outputs`` (in a supervised setting), and $w$ is an ``unknown parameter to be estimated.``\n",
    "\n",
    "\n",
    "**Examples of penalization functions**:\n",
    "\n",
    "- $\\mathrm{pen}(w) =  \\|w\\|_2^2$ (Ridge for regularization).\n",
    "\n",
    "- $\\mathrm{pen}(w) = \\|w\\|_1$ (Lasso for sparsity),\n",
    "see Tibshirani, R. (1996).\n",
    "``Regression shrinkage and selection via the lasso. Journal of the Royal Statistical Society: Series B (Methodological), 58(1), 267–288, and all extensions``\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hchUmdCdJ5mu"
   },
   "source": [
    "**First order necessary condition**\n",
    "\n",
    "Let $f : \\mathbb{R} \\to \\mathbb{R}$ be a differentiable function. If $x^{\\star}$ is a local extremum (minimum/maximum) then $f'(x^{\\star}) = 0$.\n",
    "\n",
    "Illustration from [4]. For **convex functions, we only need to look for stationary points**. This is\n",
    "not the case for potentially non-convex functions. For example, in one dimension below, all\n",
    "red points are stationary points that are not the global minimum (which is in green).\n",
    "\n",
    "\n",
    "\n",
    "![](https://drive.google.com/uc?export=view&id=1dB0TjQVALJeEVglIXDV-Bz6ZdLYT1avD)\n",
    "\n",
    "**Generalization for $d>1$**\n",
    "\n",
    "Let $f: \\mathbb{R}^d \\to \\mathbb{R}$ be a differentiable function. If $x^{\\star}$ is a local extremum then $\\nabla f(x^{\\star}) = 0$. Points such that $\\nabla f(x^{\\star}) = 0$ are called critical points. Critical points are not always extrema (consider $x \\mapsto x^3$).\n",
    "\n",
    "\n",
    "*Some useful gradients*\n",
    "\n",
    "- If $f: \\mathbb{R} \\to \\mathbb{R}$, $\\nabla f(x) = f'(x)$.\n",
    "\n",
    "- $f:x \\mapsto \\langle a,x\\rangle$: $\\nabla f(x) = a$.\n",
    "\n",
    "- $f:x \\mapsto x^T A x$: $\\nabla f(x) = (A + A^T) x$.\n",
    "\n",
    "- Particular case: $f: x \\mapsto \\|x\\|^2$, $\\nabla f(x) = 2x$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KHsehklwEooT"
   },
   "source": [
    "### <font color=darkred>Introduction : a test function -  logistic regression</font>\n",
    "\n",
    "- The objective is to predict the  label $Y\\in\\{0,1\\}$ based on $X\\in\\mathbb{R}^d$.\n",
    "\n",
    "- Logistic regression models the distribution of $Y$ given $X$.\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathbb{P}_w(Y = 1| X) = \\sigma(\\langle w,X \\rangle )\\,,\n",
    "\\end{equation*}\n",
    "where $w \\in \\mathbb{R}^d$ is a vector of model weights, and where $\\sigma$ is the sigmoid function.\n",
    "\n",
    "$$\n",
    "\\sigma: z \\mapsto \\frac{1}{1 + e^{-z}}\\,.\n",
    "$$\n",
    "\n",
    "- The sigmoid function is a model choice to map $\\mathbb{R}$ into $(0,1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kMTtxj_ukwZ3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import autograd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "plt.rcParams.update(\n",
    "    {\n",
    "        \"font.size\": 25,\n",
    "        \"figure.figsize\": (14, 7),\n",
    "        \"axes.grid\": True,\n",
    "        \"grid.color\": \"#93a1a1\",\n",
    "        \"grid.alpha\": 0.3,\n",
    "        \"axes.spines.top\": False,\n",
    "        \"axes.spines.right\": False,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ewAFvGueCup2"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    exp_x = np.exp(x)\n",
    "    return exp_x / (1 + exp_x)\n",
    "\n",
    "def sample_logistic(w0, n_samples=1000, corr=0.5):\n",
    "    n_features = w0.shape[0]\n",
    "    cov = scipy.linalg.toeplitz(corr ** np.arange(0, n_features))\n",
    "    X = np.random.multivariate_normal(np.zeros(n_features), cov, size=n_samples)\n",
    "    p = sigmoid(X.dot(w0))\n",
    "    y = np.random.binomial(1, p, size=n_samples)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 691
    },
    "id": "AgBQPvfaFLJu",
    "outputId": "6f3be9f3-b860-49b2-db43-a8b5e884b349"
   },
   "outputs": [],
   "source": [
    "n_samples = 200\n",
    "n_features = 2\n",
    "# Generate the dataset\n",
    "w0 = np.random.multivariate_normal([-3,1], np.eye(2))\n",
    "X, y = sample_logistic(w0, n_samples=n_samples, corr=0.8)\n",
    "simulated_data = pd.DataFrame.from_dict({\n",
    "    \"x1\": X[:, 0],\n",
    "    \"x2\": X[:, 1],\n",
    "    \"Label\": y\n",
    "})\n",
    "# Plot the dataset\n",
    "simulated_data[\"colors\"] = simulated_data[\"Label\"].apply(lambda label: \"C0\" if label == 1 else \"C1\")\n",
    "plt.xlabel(\"X1\")\n",
    "plt.ylabel(\"X2\")\n",
    "plt.scatter(*X.T, c=simulated_data[\"colors\"])\n",
    "plt.title(\"Logistic regression simulation\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nW9k7LGvFZM_"
   },
   "source": [
    "##### <font color=darkred>  Logistic regression: losses and gradients </font>\n",
    "\n",
    "The aim of this section is to detail how to solve the following optimization problem\n",
    "$$\n",
    "\\arg\\min_{w \\in \\mathbb{R}^d} \\Big\\{ L(w) = f(w) + \\frac{\\lambda}{2} \\|w\\|_2^2 \\Big\\}\\,,\n",
    "$$\n",
    "where $d$ is the number of features. The function **$f$ is the opposite of the normalized loglikelihood of the observations**. Therefore,\n",
    "$$\n",
    "f:w\\mapsto -\\frac{1}{n}\\log \\mathbb{P}_w(Y_{1:n} = y_{1:n}|X_{1:n}) = -\\frac{1}{n}\\sum_{i=1}^n\\log \\mathbb{P}_w(Y_{i}=y_i|X_{i})\\,,\n",
    "$$\n",
    "which yields\n",
    "$$\n",
    "L: w \\mapsto  \\frac{1}{n} \\sum_{i=1}^n \\{-y_ix_i^\\top w + \\log(1 + \\exp(x_i^\\top w))\\} + \\frac{\\lambda}{2} \\|w\\|_2^2\\,,\n",
    "$$\n",
    "where $n$ is the sample size, and where $y_i \\in \\{ 0, 1 \\}$ for all $1\\leqslant i\\leqslant n$.\n",
    "\n",
    "Note that we can write\n",
    "$$\n",
    "L: w \\mapsto  \\frac{1}{n} \\sum_{i=1}^n f_i(w)\\,,\n",
    "$$ \n",
    "where $f_i(w) = -y_ix_i^\\top w + \\log(1 + \\exp(x_i^\\top w)) + \\frac{\\lambda}{2} \\|w\\|_2^2$.\n",
    "\n",
    "An elementary gradient descent algorithm requires to compute the functions $L$ and $\\nabla L$, where\n",
    "\n",
    "$$\n",
    "\\nabla L: w \\mapsto \\frac{1}{n} \\sum_{i=1}^n (\\sigma(w^\\top x_i)-y_i)x_i + \\lambda w\\,.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>  Write a class LogisticRegression containing the follwing methods.</font>\n",
    "\n",
    "<font color=darkred>- ``loss``: returns the loss function. </font>\n",
    "    \n",
    "<font color=darkred>- ``grad``: returns the gradient of the loss function.</font>\n",
    "    \n",
    "<font color=darkred>- ``grad_fi``: returns the gradient of the loss function.</font>\n",
    "    \n",
    "<font color=darkred>- ``grad_coordinate``: returns the gradient of the loss function.</font>\n",
    "    \n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "01ULwRpyFeLM"
   },
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, X, y, lambd):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.lambd = lambd\n",
    "        self.n_samples, self.n_features = X.shape\n",
    "\n",
    "    def loss(self, w):\n",
    "        # Computes f(w)\n",
    "        res = sum([\n",
    "            np.log(1 + np.exp(observation @ w)) - label * observation @ w\n",
    "            for observation, label in zip(self.X, self.y)\n",
    "        ]) / self.n_samples\n",
    "        res += self.lambd*0.5*(np.linalg.norm(w)**2)\n",
    "        return res\n",
    "\n",
    "    def grad(self, w):\n",
    "        # Computes the gradient of f at w\n",
    "        res = sum([\n",
    "            -label * observation + np.exp(observation @ w) / (1 + np.exp(observation @ w)) * observation\n",
    "            for observation, label in zip(self.X, self.y)\n",
    "        ]) / self.n_samples\n",
    "        res += self.lambd * w\n",
    "        return res\n",
    "\n",
    "    def grad_fi(self, i, w):\n",
    "        # Computes the gradient of f_i at w\n",
    "        return -y[i] * self.X[i] + np.exp(self.X[i] @ w) / (1 + np.exp(self.X[i] @ w)) * self.X[i] + self.lambd * w\n",
    "\n",
    "    def grad_coordinate(self, j, w):\n",
    "        # Computes the partial derivative of f with respect to the j-th coordinate\n",
    "        res = sum([\n",
    "            -label * observation[j] + np.exp(observation @ w) / (1 + np.exp(observation @ w)) * observation[j]\n",
    "            for observation, label in zip(self.X, self.y)\n",
    "        ]) / self.n_samples\n",
    "        res += self.lambd * w[j]\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MRh_BL8MFvOD",
    "outputId": "d3afb10b-d2f0-4ab3-9224-0eab6733c8be"
   },
   "outputs": [],
   "source": [
    "# Check numerically the gradient using the function checkgrad from scipy.optimize\n",
    "# Use the function sample_logistic to simulate data according to the logistic regression model\n",
    "n_features = 10\n",
    "w_true = np.random.randn(n_features)\n",
    "X, y = sample_logistic(w_true, n_samples, corr=0.9)\n",
    "model = LogisticRegression(X, y, 1e-3)\n",
    "# check_grad assesses the correctness of a gradient by comparing it to a finite-difference approximation\n",
    "scipy.optimize.check_grad(model.loss, model.grad, w_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-LLKyj4F2wD"
   },
   "source": [
    "### <font color=darkred> Part I : First order approaches </font>\n",
    "\n",
    "The most simple method  is based on **full gradients**, since at each iteration  it requires to compute\n",
    "$$\n",
    "\\nabla f(w) = \\frac 1n \\sum_{i=1}^n \\nabla  f_i(w)\\,,\n",
    "$$\n",
    "which depends on the **whole dataset**. When processing very large datasets ($n$ is large), this approach has a highly prohibitive computational cost  for a  unique step towards the minimum.\n",
    "For all $k\\geqslant 1$, set\n",
    "$$\n",
    "w^{(k)} = w^{(k-1)} - \\eta_k \\nabla f_{}(w^{(k-1)})\\,.\n",
    "$$\n",
    "Each iteration has complexity $O(nd)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GxDZ_IL_GF4v"
   },
   "source": [
    "##### <font color=darkred> Full gradient descent </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0oEotU_NHkP"
   },
   "source": [
    "- ``Input``: Function $f$ to minimize, initial vector $w^{(0)}$, $k=0$.\n",
    "\n",
    "- Parameters: step size $\\eta_k>0$, $k\\geq 1$.\n",
    "\n",
    "While not converge do\n",
    "\n",
    "- $w^{(k+1)} = w^{(k)} - \\eta_{k+1} \\nabla f(w^{(k)})$.\n",
    "\n",
    "- $k = k+1$.\n",
    "\n",
    "- ``Output``: $w^{(n_*)}$ where $n_*$ is the last iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "juGqbmMcP52f"
   },
   "source": [
    "###### **Implementation from scratch**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>  Write a function ``gradient_descent`` with the proposed inputs and outputs.</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H7RttK4rF1jK"
   },
   "outputs": [],
   "source": [
    "def gradient_descent(model, w0, iterations, step_size):\n",
    "    loss_history = []\n",
    "    w = w0.copy()\n",
    "    for k in range(iterations):\n",
    "        w = w - step_size * model.grad(w)\n",
    "        loss_history.append(model.loss(w))\n",
    "    return w, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 661
    },
    "id": "JDHIpBjkGZ35",
    "outputId": "28ff8313-3b07-4978-be41-e6ac7e93082a"
   },
   "outputs": [],
   "source": [
    "# We compare the following step sizes\n",
    "compared_step_sizes = [1e-2, 1e-1, 5e-1 ,1]\n",
    "# Weights are initialized once at random\n",
    "w0 = np.random.randn(n_features)\n",
    "iterations = 500\n",
    "for step_size in compared_step_sizes:\n",
    "    _, loss_history = gradient_descent(model, w0, iterations, step_size)\n",
    "    plt.plot(loss_history, '-', lw=3, label=f\"Step size {step_size}\")\n",
    "# Configure plot\n",
    "plt.title('Gradient descent')\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Negative loglikelihood')\n",
    "plt.tight_layout()\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKZSsUyjQUQW"
   },
   "source": [
    "###### **Implementation with torch**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>  Write a class ``LogisticRegressionTorch`` using torch to write a method ``gradient_descent``</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D6Jpiz0TPO-O"
   },
   "outputs": [],
   "source": [
    "class LogisticRegressionTorch(LogisticRegression):\n",
    "    def __init__(self, X, y, lambd):\n",
    "        # Start with the same initialization\n",
    "        super().__init__(X, y, lambd)\n",
    "        # Convert dataset to tensors\n",
    "        self.X = torch.tensor(self.X)\n",
    "        self.y = torch.tensor(self.y).unsqueeze(-1).double()\n",
    "        # Define the layer for the dot product\n",
    "        self.layer = torch.nn.Linear(self.n_features, 1, bias=False)\n",
    "        # Define the gradient descent optimizer\n",
    "        self.optimizer = torch.optim.SGD(self.layer.parameters(), lr=1e-1)\n",
    "\n",
    "    def loss(self, w):\n",
    "        # Set the parameters of the layer to the input ``w``\n",
    "        self.layer.weight.data = torch.tensor(w).unsqueeze(0)\n",
    "        # Compute the regularized cross entropy loss\n",
    "        return F.binary_cross_entropy(\n",
    "            F.sigmoid(self.layer(self.X)),\n",
    "            self.y\n",
    "        ) + torch.norm(self.layer.weight).square() * self.lambd / 2\n",
    "\n",
    "    def grad(self, w):\n",
    "        # Reset the gradient attached to ``w``\n",
    "        # By default, torch adds up new gradient computations, unlike tensorflow or mxnet\n",
    "        self.layer.zero_grad()\n",
    "        self.loss(w).backward()\n",
    "        return self.layer.weight.grad\n",
    "\n",
    "    def gradient_descent(self, w, iterations, step_size):\n",
    "        # Set the parameters of the layer to the input ``w``\n",
    "        self.layer.weight.data = torch.tensor(w).unsqueeze(0)\n",
    "        optimizer = torch.optim.SGD(self.layer.parameters(), lr=step_size)\n",
    "        hist = []\n",
    "        for _ in range(iterations):\n",
    "            # Reset the gradient attached to ``w``\n",
    "            # By default, torch adds up new gradient computations, unlike tensorflow or mxnet\n",
    "            optimizer.zero_grad()\n",
    "            # Compute the regularized cross entropy loss\n",
    "            loss = F.binary_cross_entropy(\n",
    "                F.sigmoid(self.layer(self.X)),\n",
    "                self.y\n",
    "            ) + torch.norm(self.layer.weight).square() * self.lambd / 2\n",
    "            # Compute the gradient of the loss with respect to the input ``w``\n",
    "            loss.backward()\n",
    "            # Take on gradient step\n",
    "            optimizer.step()\n",
    "            # Log the initial loss value\n",
    "            hist.append(loss.item())\n",
    "        return self.layer.weight.data.detach().numpy(), hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vX2I1rtC5_i0",
    "outputId": "84e8d94c-c2b4-4e22-8c32-79504404fc63"
   },
   "outputs": [],
   "source": [
    "model_torch = LogisticRegressionTorch(X, y, lambd=1e-3)\n",
    "\n",
    "print(\"Loss for w0:\")\n",
    "print(\"\\tHandmade model:\\t\", model.loss(w0))\n",
    "print(\"\\tTorch model:\\t\", model_torch.loss(w0).item())\n",
    "print(\"Gradient of w0:\")\n",
    "print(\"\\tHandmade model:\\t\", model.grad(w0))\n",
    "print(\"\\tTorch model:\\t\", model_torch.grad(w0).numpy().squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 661
    },
    "id": "j65sBXWK6g2G",
    "outputId": "cfafd34e-d8ce-4d69-c19b-08ca29820551"
   },
   "outputs": [],
   "source": [
    "# We compare the following step sizes\n",
    "compared_step_sizes = [1e-2, 1e-1, 5e-1 ,1]\n",
    "# Weights are initialized once at random\n",
    "w0 = np.random.randn(n_features)\n",
    "iterations = 500\n",
    "for step_size in compared_step_sizes:\n",
    "    _, loss_history = model_torch.gradient_descent(w0, iterations, step_size)\n",
    "    plt.plot(loss_history, '-', lw=3, label=f\"Step size {step_size}\")\n",
    "# Configure plot\n",
    "plt.title('Gradient descent')\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Negative loglikelihood')\n",
    "plt.tight_layout()\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qhz2ybCpQcCm"
   },
   "source": [
    "###### **Convergence**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5uUq9t2INi1D"
   },
   "source": [
    "``Convex function``\n",
    "\n",
    "A function $f : \\mathbb{R}^d \\to \\mathbb{R}$ is convex on $\\mathbb{R}^d$ if, for all $x, y \\in \\mathbb{R}^d$, for all $\\lambda \\in [0,1]$,\n",
    "$$\n",
    "f(\\lambda x + (1- \\lambda) y ) \\leq \\lambda f(x) + (1 - \\lambda) f(y).\n",
    "$$\n",
    "Illustration of a convex function from [1].\n",
    "![](https://drive.google.com/uc?export=view&id=17AZASkc-y_ZH-MDGPgmqDkuVfnYKU6-k)\n",
    "\n",
    "\n",
    "Illustration of a strongly convex function from [4].\n",
    "![](https://drive.google.com/uc?export=view&id=1tRnGMLa6Yw1vGUl8EnxBLTg_VEN9ay7T)\n",
    "\n",
    "``$L$-smooth function``\n",
    "\n",
    "A function $f$ is said to be $L$-smooth if $f$ is differentiable and if, for all $x, y \\in \\mathbb{R}^d$,\n",
    "$$\n",
    "\\| \\nabla f(x) - \\nabla f(y) \\| \\leqslant L \\|x-y\\|\\,.\n",
    "$$\n",
    "\n",
    "If $f$ is twice differentiable, this is equivalent to writing that for all $x \\in \\mathbb{R}^d$,  \n",
    "\n",
    "$$\n",
    "\\lambda_{max} (\\nabla^2 f(x)) \\leqslant L,\n",
    "$$\n",
    "where $\\lambda_{max}(A)$ is the largest eigenvalue of a matrix $A$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BgyOC4IaOBNg"
   },
   "source": [
    "Let $f : \\mathbb{R}^d \\to \\mathbb{R}$ be a $L$-smooth convex function. Let $w^{\\star}$ be a minimum of $f$ on $\\mathbb{R}^d$. Then, Gradient Descent with step size $\\eta \\leqslant 1/L$ satisfies\n",
    "\n",
    "\\begin{align*}\n",
    "f(w^{(k)}) - f(w^{\\star}) \\leqslant \\frac{\\|w^{(0)} - w^{\\star}\\|_2^2}{2 \\eta k}\\,.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S95VS4aAUunq"
   },
   "source": [
    "**Remark**\n",
    "\n",
    "Consider a quadratic convex functions, i.e. a function $f$ such that  $f: w\\mapsto w^\\top Hw/2 - c^\\top w$ with $c\\in\\mathbb{R}$ and $H$ a symmetric positive definite matrix in $\\mathbb{R}^{d\\times d}$. In this case, $f$ is $\\mu$-strongly convex and $L$- smooth with $\\mu$ (resp. $L$) the smallest (resp. largest) eigenvalues of $H$. As for all $w\\in\\mathbb{R}^d$, $\\nabla f(w) = Hw -c$, the unique minimum of $f$ is $w^\\star = H^{-1}c$ and for all $k\\geqslant 1$,\n",
    "$$\n",
    "w^{(k+1)} = w^{(k)} - \\eta_{k+1}\\left(Hw^{(k)}-c\\right) = w^{(k)} - \\eta_{k+1} H\\left(w^{(k)}-w^\\star\\right)\\,,\n",
    "$$\n",
    "which yields\n",
    "$$\n",
    "w^{(k+1)}- w^\\star = \\left(I_d - \\eta_{k+1} H\\right)\\left(x^{(k)}-w^\\star\\right) = \\left(I_d - \\eta H\\right)^k\\left(w^{(1)}-w^\\star\\right)\\,,\n",
    "$$\n",
    "when for all $k\\geq 1$, $\\eta_k = \\eta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Kr6kYipGenw"
   },
   "source": [
    "##### <font color=darkred> Stochastic gradient descent </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h4FpBRuVQx5f"
   },
   "source": [
    "Previous methods are based on full gradients, since each iteration requires the computation of\n",
    "\t\\begin{equation*}\n",
    "\t\t\\quad \\nabla f(w) = \\frac 1n \\sum_{i=1}^n \\nabla  f_i(w),\n",
    "\t\\end{equation*}\n",
    "\twhich depends on the **whole dataset**\n",
    "\t.\n",
    "  \n",
    "  If $n$ is large, computing $\\nabla f(w)$ is computationally expensive. If $I$ is  chosen uniformly at random in $\\{ 1, \\ldots, n \\}$, then\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbb{E}[ \\nabla f_I(w) ] =\n",
    "\\frac 1n \\sum_{i=1}^n \\nabla f_{i}(w) = \\nabla f(w)\\,,\n",
    "\\end{align*}\n",
    "\n",
    "**$\\nabla f_I(w)$ is an unbiased but very noisy estimate of the full gradient $\\nabla f(w)$**.\n",
    "\n",
    "Computation of $\\nabla f_I(w)$ only requires the $I$-th observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ND-cEwafRPCK"
   },
   "source": [
    "``Input``: starting point $w^{(0)}$, steps (learning rates) $\\eta_k$\n",
    "\n",
    "`- For $k = 1, 2, \\ldots$ until convergence do\n",
    "\n",
    "- Pick at random (uniformly) $I_k$ in $\\{ 1, \\ldots, n \\}$.\n",
    "\n",
    "- Compute\n",
    "\\begin{equation*}\n",
    "w^{(k)} = w^{(k-1)} - \\eta_k \\nabla f_{I_k}(w^{(k-1)})\\,.\n",
    "\\end{equation*}\n",
    "\n",
    "``Output``:  last $w^{(n_*)}$.\n",
    "\n",
    "\n",
    "\n",
    "Each iteration has complexity $O(d)$ instead of\n",
    "$O(nd)$ for full gradient methods.\n",
    "\n",
    "Of course, a best trade-off (estimator of the full gradient with a lower variance than using only one observation but still at a better cost than a full gradient update) is obtained by **using a batch of observations at each time step**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S62gptpbRdMQ"
   },
   "source": [
    "###### **Implementation from scratch**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>  Write a function ``sgd`` with the proposed inputs and outputs.</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qb1xANmrGifT"
   },
   "outputs": [],
   "source": [
    "def sgd(model, w0, iterations, step_size, alpha):\n",
    "    loss_val  = np.zeros(iterations)\n",
    "    w = w0.copy()\n",
    "    n_samples = model.n_samples\n",
    "    for idx in range(iterations):\n",
    "        i = np.random.randint(0, model.n_samples)\n",
    "        w = w - step_size * model.grad_fi(i,w) / ((idx+1)**alpha)\n",
    "        loss_val[idx] = model.loss(w)\n",
    "    return w, loss_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred> Run ``sgd`` with different values for the step-sizes.</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 661
    },
    "id": "zolxZZ91Gimu",
    "outputId": "f46585b0-b87e-4774-d724-a307a9d24f7c"
   },
   "outputs": [],
   "source": [
    "# We compare the following values for alpha\n",
    "compared_alphas = [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "# Weights are initialized once at random\n",
    "w0 = np.random.randn(n_features)\n",
    "step_size = 0.5\n",
    "iterations = 700\n",
    "for alpha in compared_alphas:\n",
    "    _, loss_history = sgd(model, w0, iterations, step_size, alpha)\n",
    "    plt.plot(loss_history, '-', lw=3, label=f\"$\\\\alpha={alpha}$\")\n",
    "# Configure plot\n",
    "plt.title('Stochastic gradient descent')\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Negative loglikelihood')\n",
    "plt.tight_layout()\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6YaiZKs_Rfqm"
   },
   "source": [
    "###### **Implementation with torch**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>  Update the ``LogisticRegressionTorch`` class to use SGD to train model parameters.</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cAYbXHnMRi3B"
   },
   "outputs": [],
   "source": [
    "class LogisticRegressionTorch(LogisticRegression):\n",
    "    def __init__(self, X, y, lambd):\n",
    "        super().__init__(X, y, lambd)\n",
    "        self.X = torch.tensor(self.X)\n",
    "        self.y = torch.tensor(self.y).unsqueeze(-1).double()\n",
    "        self.layer = torch.nn.Linear(self.n_features, 1, bias=False)\n",
    "\n",
    "    # We now consider the loss as a function of observations and labels\n",
    "    # This is the torch way\n",
    "    def loss(self, X, y):\n",
    "        return F.binary_cross_entropy(\n",
    "            F.sigmoid(self.layer(X)),\n",
    "            y\n",
    "        ) + torch.norm(self.layer.weight).square() * self.lambd\n",
    "\n",
    "    def sgd(self, w, iterations, lr, alpha):\n",
    "        # In practice, weights are directly initialized by the layer\n",
    "        # And we don't manually set its value\n",
    "        self.layer.weight.data = torch.tensor(w).unsqueeze(0)\n",
    "        optimizer = torch.optim.SGD(self.layer.parameters(), lr=lr)\n",
    "        hist = []\n",
    "        for idx in range(iterations):\n",
    "            # Reset gradient\n",
    "            optimizer.zero_grad()\n",
    "            # Select a random sample in the dataset\n",
    "            i = np.random.randint(0, self.n_samples)\n",
    "            # Compute the loss and the gradient for this sample\n",
    "            self.loss(self.X[i:i+1], self.y[i:i+1]).backward()\n",
    "            self.layer.weight.grad /= ((idx+1)**alpha)\n",
    "            # Update the parameters w\n",
    "            optimizer.step()\n",
    "            # Log the loss on the full dataset\n",
    "            hist.append(self.loss(self.X, self.y).item())\n",
    "        return w, hist\n",
    "model_torch = LogisticRegressionTorch(X, y, lambd=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 661
    },
    "id": "LNPCAl43fZdA",
    "outputId": "f1d313c8-643f-4069-d963-583b85ebf37f"
   },
   "outputs": [],
   "source": [
    "# We compare the following values for alpha\n",
    "compared_alphas = [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "# Weights are initialized once at random\n",
    "w0 = np.random.randn(n_features)\n",
    "step_size = 0.5\n",
    "iterations = 700\n",
    "for alpha in compared_alphas:\n",
    "    _, loss_history = model_torch.sgd(w0, iterations, lr=step_size, alpha=alpha)\n",
    "    plt.plot(loss_history, '-', lw=3, label=f\"$\\\\alpha={alpha}$\")\n",
    "# Configure plot\n",
    "plt.title('Stochastic gradient descent')\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Negative loglikelihood')\n",
    "plt.tight_layout()\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LsYGbz9RjBr"
   },
   "source": [
    "###### **Convergence**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9kWmI0URkOF"
   },
   "source": [
    "Project each estimate into the ball $B(0,R)$ with $R>0$ fixed.\n",
    "\n",
    "Let\n",
    "$$\n",
    "f (x) = \\frac{1}{n} \\sum_{i=1}^n f_i(x)\\,.\n",
    "$$\n",
    "\n",
    "\n",
    "Assume that $f$ is convex and that there exists $b>0$ satisfying, for all $x \\in B(0,R)$,\n",
    "$$\n",
    "\\|\\nabla f_i (x)\\| \\leqslant b\\,.\n",
    "$$\n",
    "\n",
    "Assume also that all minima of $f$ belong to $B(0,R)$. Then, setting $\\eta_k = 2R/(b\\sqrt{k})$,\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbb{E}\\bigg[ f\\Big( \\frac{1}{k} \\sum_{j = 1}^k w^{(j)}\\Big)\\bigg] - f(w^{\\star}) \\leq \\frac{3Rb}{\\sqrt{k}}\\,.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DD2W9IhQGxsp"
   },
   "source": [
    "##### <font color=darkred> Coordinate gradient descent </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AoM5HjK1R-XF"
   },
   "source": [
    "###### **Implementation from scratch**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>  Write a function ``coordinate_gd`` to propose an update coordinate by coordinate.</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hKpBrUSWGx37"
   },
   "outputs": [],
   "source": [
    "def coordinate_gd(model, w0, iterations, step_size):\n",
    "    w = w0.copy()\n",
    "    loss_history = []\n",
    "    n_features = model.n_features\n",
    "    for k in range(iterations):\n",
    "        for j in range(n_features):\n",
    "            w[j] = w[j] - step_size * model.grad_coordinate(j, w)\n",
    "        loss_history.append(model.loss(w))\n",
    "    return w, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 661
    },
    "id": "tkOzn5pbGx8Y",
    "outputId": "5a42f96b-969e-490f-e471-850975d0ba93"
   },
   "outputs": [],
   "source": [
    "step_size = 1e-1\n",
    "iterations = 500\n",
    "# Compute coordinate gradient descent\n",
    "_, loss_history = coordinate_gd(model, w0, iterations, step_size)\n",
    "# Plot loss history\n",
    "plt.plot(loss_history, lw=3)\n",
    "plt.title('Coordinate gradient descent')\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Negative loglikelihood')\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3JoduGojHCkO"
   },
   "source": [
    "### <font color=darkred> Part II : Accelerated approaches </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHtCIynPaj8d"
   },
   "source": [
    "Gradient descent take a long time to converge in nearly flat surface as shown in this flat optimization landscape from [5].\n",
    "![](https://drive.google.com/uc?export=view&id=1etWh6TQOHmGIlxswZZyXtHv4L80renl5)\n",
    "\n",
    "\n",
    "Allowing momentum to accumulate is one way to speed progress.\n",
    "All gradient descent algorithms can be updated by allowing momentum to accumulate:\n",
    "$v^{(k+1)} = \\beta v^{\n",
    "(k)} − \\alpha \\nabla f\n",
    "(w^{(k)})$ and $w^{(k+1)} = w^{\n",
    "(k)} + v^{(k+1)}$. When $\\beta = 0$, we recover standard gradient descent.  The rationale is that gradient causes momentum to accumulate to improve speed of convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_kXlfyDHCra"
   },
   "source": [
    "##### <font color=darkred> Nesterov accelerated gradient descent </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXJ9eT_JdnJk"
   },
   "source": [
    "One issue of momentum is that the steps do not slow down enough when the parameters reach the local minimum. Nesterov momentum modifies the momentum algorithm to use the gradient at the projected future position to overcome this difficulty.\n",
    "``Y. Nesterov, A Method of Solving\n",
    "a Convex Programming Problem\n",
    "with Convergence Rate O(1/k^2),\n",
    "Soviet Mathematics Doklady, vol. 27,\n",
    "no. 2, pp. 543–547, 1983.``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4i5XSNZvR-V1"
   },
   "source": [
    "``Input``: starting point $w^{(0)}$, learning rate $\\eta_k > 0$, initial velocity $v^{(0)}=0$, momentum $\\beta_k \\in [0,1]$.\n",
    "\n",
    "While not converge do    \n",
    "\n",
    "- $v^{(k+1)} = w^{(k)} - \\eta \\nabla f (w^{(k)})$.\n",
    "\n",
    "- $w^{(k+1)} = v^{(k+1)} + \\beta_{k+1}( v^{(k+1)} - v^{(k)})$.\n",
    "\n",
    "``Output``: last $w^{(n_*)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5Akuj_jjRm3"
   },
   "source": [
    "Illustration of Nesterov's acceleration from [5].\n",
    "\n",
    "![](https://drive.google.com/uc?export=view&id=1rp-Eq60V2w_WV669ZFrqLBHyviiih_rK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44dUMXBvSQ3p"
   },
   "source": [
    "###### **Implementation from scratch**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>  Write a function ``nesterov_gd`` with the proposed inputs and outputs.</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mJ2Fks3aHC8m"
   },
   "outputs": [],
   "source": [
    "def nesterov_gd(model, w, iterations, step_size, beta):\n",
    "    loss_history = []\n",
    "    v = w.copy()\n",
    "    for k in range(iterations):\n",
    "        v_new = w - step_size * model.grad(w)\n",
    "        w = v + beta * (v_new - v)\n",
    "        v = v_new\n",
    "        loss_history.append(model.loss(w))\n",
    "    return w, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 661
    },
    "id": "NqGNhBNhHDCP",
    "outputId": "ff5f04bb-53fa-4f64-bf47-05a448ce367b"
   },
   "outputs": [],
   "source": [
    "beta = 0.95\n",
    "step_size = 1e-1\n",
    "iterations = 500\n",
    "# Compute Nesterov gradient descent\n",
    "w, loss_history = nesterov_gd(model, w0, iterations, step_size, beta)\n",
    "\n",
    "# Plot loss history\n",
    "plt.plot(loss_history, lw=3)\n",
    "plt.title('Nesterov gradient descent')\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Negative loglikelihood')\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0BvQRE0RSSyq"
   },
   "source": [
    "###### **Implementation with torch**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RKolER_afvxe"
   },
   "source": [
    "Simply switch\n",
    "```python\n",
    "optimizer = torch.optim.SGD(self.layer.parameters(), lr=lr)\n",
    "```\n",
    "to\n",
    "```python\n",
    "optimizer = torch.optim.SGD(self.layer.parameters(), lr=lr, nesterov=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hv7PC9NrSTHB"
   },
   "source": [
    "###### **Convergence**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fF6Yib35SJKW"
   },
   "source": [
    "Assume that $f$ is a **$L$-smooth, convex function whose minimum is reached at $w^{\\star}$**. Then, if $\\beta_{k+1} = k/(k+3)$,\n",
    "\n",
    "\\begin{align*}\n",
    "f(w^{(k)}) - f(w^{\\star}) \\leq \\frac{2 \\|w^{(0)} - w^{\\star}\\|_2^2}{\\eta (k+1)^2}\\,.\n",
    "\\end{align*}\n",
    "\n",
    "Assume that $f$ is a **$L$-smooth, $\\mu$ strongly convex function whose minimum is reached at $w^{\\star}$**. Then, choosing\n",
    "$$\n",
    "\\beta_{k} = \\frac{1 - \\sqrt{\\mu/L}}{1 + \\sqrt{\\mu/L}},\n",
    "$$\n",
    "yields\n",
    "\n",
    "\\begin{align*}\n",
    "f(w^{(k)}) - f(w^{\\star}) \\leq \\frac{ \\|w^{(0)} - w^{\\star}\\|_2^2}{\\eta} \\Big( 1 - \\sqrt{\\frac{\\mu}{L}}\\Big)^k\\,.\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hf52Jz_pTDKX"
   },
   "source": [
    "##### <font color=darkred> ADAptive GRADient and AdaDelta algorithms </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fp8QfK-dg9Zk"
   },
   "source": [
    "The adaptive subgradient method adapts the learning rate for each component of the parameter $w^{(k)}$. Adagrad weakens the influence of parameters with\n",
    " high gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFmxHUzBTDXG"
   },
   "source": [
    "``Input``: starting point $w^{(0)}$, learning rate $\\eta > 0$, momentum $\\alpha$.\n",
    "\n",
    "For $k = 1, 2, \\ldots$ until convergence do    \n",
    "\n",
    "- For all $j = 1, \\ldots , d$, apply the step\n",
    "\t\\begin{equation*}\n",
    "\tw_j^{(k+1)} \\gets w_j^{(k)}\n",
    "\t- \\frac{\\eta}{\\varepsilon + \\sqrt{\\sum_{\\tau=1}^k (\\nabla f (w^{(\\tau)}))_j^2}} (\\nabla f(w^{(k)}))_j\n",
    "\t\\end{equation*}\n",
    "\n",
    "``Output``: last $w^{(n_*)}$\n",
    "\n",
    "\n",
    "``AdaDelta`` was introduced in https://arxiv.org/pdf/1212.5701.pdf (Zeiler, 2012) to reduce the sensitivity to initial conditions of AdaGrad. Indeed, if the initial gradients are large, the learning rates of AdaGrad will be low for all updates.  AdaDelta aims at avoiding the effect of a monotonically decreasing learning rate by replacing $\\eta$ by an adaptive rate (exponentially decaying average of the square updates).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yaPYsb69Spbg"
   },
   "source": [
    "###### **Implementation with torch**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mmsowfjT0hIj"
   },
   "source": [
    "Switch\n",
    "```python\n",
    "optimizer = torch.optim.SGD(self.layer.parameters(), lr=lr)\n",
    "```\n",
    "for AdaGrad to:\n",
    "```python\n",
    "optimizer = torch.optim.Adagrad(self.layer.parameters(), lr=lr)\n",
    "```\n",
    "or for AdaDelta to:\n",
    "```python\n",
    "optimizer = torch.optim.Adadelta(self.layer.parameters(), lr=lr)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "343eL3Ti_-86"
   },
   "source": [
    "##### <font color=darkred> ADAM: Adaptive moment estimation </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KZ1WfIpyTZcS"
   },
   "source": [
    "``ADAM`` was introduced in https://arxiv.org/pdf/1412.6980.pdf (Kingma et al., 2014) and **is considered as the state of the art to otpimize neural networks**, the ADAM procedure update the parameter estimate as follows.\n",
    "\n",
    "``Input`` $m_0 = 0$ and $v_0=0$ and choosing $\\beta_1, \\beta_2, \\eta, \\varepsilon\n",
    " \\in (0,1)$,\n",
    "\n",
    " - Compute first and second moment estimate\n",
    "$$\n",
    "m_k = \\beta_1 m_{k-1} + (1 - \\beta_1) \\nabla f (w^{(k)}) \\quad  \\mathrm{and} \\quad v_k = \\beta_2 v_{k-1} + (1 - \\beta_2) (\\nabla f (w^{(k)}))^2\\,,\n",
    "$$\n",
    "\n",
    "- Compute the correction terms\n",
    "$$\n",
    "\\hat{m}_k = \\frac{m_k}{1 - \\beta_1^k} \\quad \\hat{v}_k = \\frac{v_k}{1 - \\beta_2^k}\\,,\n",
    "$$\n",
    "\n",
    "- Update the parameter estimate with\n",
    "$$\n",
    "w^{(k+1)} = w^{(k)} - \\frac{\\eta}{\\sqrt{\\hat{v}_k}+ \\varepsilon} \\hat{m}_k\\,.\n",
    "$$\n",
    "First convergence results can be found in https://arxiv.org/pdf/1412.6980.pdf (Kingma et al., 2014) and examples where ADAM algorithm does not converge to the optimum are given in https://openreview.net/pdf?id=ryQu7f-RZ (Reddi et al., 2018). Recent analysis by https://arxiv.org/abs/1810.02263 (Barakat et al., 2018)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3eLNxuHSuab"
   },
   "source": [
    "###### **Implementation with torch**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R6kCWn-V0lWX"
   },
   "source": [
    "Switch\n",
    "```python\n",
    "optimizer = torch.optim.SGD(self.layer.parameters(), lr=lr)\n",
    "```\n",
    "to:\n",
    "```python\n",
    "optimizer = torch.optim.Adam(self.layer.parameters(), lr=lr)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
