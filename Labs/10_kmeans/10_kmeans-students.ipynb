{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=darkcyan> K-means algorithm</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The K-means algorithm is a procedure which aims at partitioning a data set into $K$ distinct, non-overlapping clusters.\n",
    "Consider $n\\geqslant 1$ observations $(X_{1},\\ldots,X_{n})$ taking values in $\\mathbb{R}^p$.\n",
    "The $K$-means algorithm seeks to minimize over all partitions $C = (C_{1},\\ldots,C_{K})$ of $\\{1,\\ldots,n\\}$ the following criterion\n",
    "$$\n",
    "\\textrm{crit}(C)=\\sum_{k=1}^K{1\\over |C_{k}|}\\sum_{a,b\\in C_{k}} \\|X_{a}-X_{b}\\|^2\\,,\n",
    "$$\n",
    "where for all $1\\leqslant i\\leqslant n$, $1\\leqslant k\\leqslant K$, $i\\in C_k$ if and only if $X_i$ is in the $k$-th cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all $j$, we write $\\bar{X}_{C_j}$ for the empirical mean of data with index in $C_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the distance between two clusters $1\\leqslant i,j\\leqslant K$ as \n",
    "$$\n",
    "d(C_i,C_j) = \\sum_{a\\in C_i\\cup C_j}\\|X_{a}-\\bar{X}_{C_{i}\\cup C_j}\\|^2 - \\sum_{a\\in C_i}\\|X_{a}-\\bar{X}_{C_i}\\|^2 -\\sum_{a\\in  C_j}\\|X_{a}-\\bar{X}_{C_j}\\|^2\\,.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>Prove that for all $1\\leqslant i,j\\leqslant K$,\n",
    "$$\n",
    "d(C_i,C_j) = \\frac{|C_i||C_j|}{|C_i|+|C_j|}\\|\\bar{X}_{C_{i}}-\\bar{X}_{C_{j}}\\|^2\\,.\n",
    "$$\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>  Establish that\n",
    "$$\n",
    "\\textrm{crit}(C)= 2\\sum_{k=1}^K{1\\over |C_{k}|}\\sum_{a,b\\in C_{k}} \\langle X_{a},X_{a}-X_{b}\\rangle = 2\\sum_{k=1}^K\\sum_{a\\in C_{k}}\\|X_{a}-\\bar{X}_{C_{k}}\\|^2\\,,\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\bar{X}_{C_{k}}={1\\over |C_{k}|}\\sum_{b\\in C_{k}} X_{b}\\,.\n",
    "$$</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data \n",
    "np.random.seed(42)\n",
    "data1 = np.random.randn(100, 2) + np.array([3, 3])\n",
    "data2 = np.random.randn(100, 2) + np.array([-5, 0])\n",
    "data3 = np.random.randn(100, 2) + np.array([1, -3])\n",
    "data = np.concatenate([data1, data2, data3])\n",
    "plt.scatter(data[:, 0], data[:, 1], marker='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=darkred>  Kmeans algorithm </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the set of k means: $m_1(1), ..., m_k(1)$. Then, each iteration $p\\geq 1$ is decomposed into two steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Association step**: each observation is associated with the cluster with the nearest mean in Euclidean distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Update step**: Compute the new mean of each cluster $m_1(p+1), ..., m_k(p+1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>Prove that the criterion monotonically decreases with the iterations of the K-means algorithm.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=darkred>  From scratch </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "\n",
    "Write a ``kmeans`` function with arguments the data ``X``, the number of clusters ``k``, the maximum number of iterations ``max_iter`` and the tolerance for the convergence of centers ``tol``. The function returns the labels ``labels`` and the centers ``centroids``\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(X, k, max_iter=1000, tol=1e-5):\n",
    "    \n",
    "    n, d = X.shape\n",
    "    \n",
    "    # Initialize centers randomly\n",
    "    centroids = X[np.random.choice(n, k, replace=False)]\n",
    "    \n",
    "    for iter in range(max_iter):\n",
    "        # Compute the distance between the centers and data points and assignment of labels\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convergence of the algorithm depends on the initialization and the quality of the final clustering needs to be assessed with some specific criterion. We discuss these issues using ``sklearn``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=darkred>  Kmeans with Sklearn </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>Load the digits dataset from sklearn</font>\n",
    "\n",
    "Each datapoint is a 8x8 image of a digit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_digits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the observations are high dimensional, vizualizations of kmeans output is not easy. We first propose to use a PCA to work with a low dimensional dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>Perform a PCA with 2 components</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>Perform a Kmeans classification with ``n_digits`` classes</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inertia criterion is the sum of distances of samples to their closest cluster center\n",
    "\n",
    "<font color=darkred>Display the impact of the number of clusters on the total inertia</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initialization of the algorithm may have an impact on the convergence as it converges to a local minimum.\n",
    "\n",
    "<font color=darkred>Compare the impact of different initialization methods</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``k-means++`` selects initial cluster centroids using sampling based on an empirical probability distribution of the data. This technique speeds up convergence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The elbow method aims at automatically selecting a value for  K. The elbow graph displays the within-cluster-sum-of-square (squared distances between clusters) values as a function of K. The selected value of K value is the point at which the graph forms an elbow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>Use the Kmeans algorithm to cluster data from the Iris dataset. Display the different clusters and compare to the true label of the data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
